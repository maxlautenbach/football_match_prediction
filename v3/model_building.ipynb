{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6f61b8",
   "metadata": {},
   "source": [
    "# Football Match Prediction - Clean Model Building\n",
    "\n",
    "Saubere Implementation mit RandomForest und umfassendem Hyperparameter-Tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00ceda30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (4832, 67)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teamHomeId</th>\n",
       "      <th>teamAwayId</th>\n",
       "      <th>matchDay</th>\n",
       "      <th>season</th>\n",
       "      <th>teamHomeValue</th>\n",
       "      <th>teamAwayValue</th>\n",
       "      <th>teamHomeAvgScoredGoals1</th>\n",
       "      <th>teamHomeAvgGottenGoals1</th>\n",
       "      <th>teamHomeAvgTeamPoints1</th>\n",
       "      <th>teamHomeAvgScoredGoals2</th>\n",
       "      <th>...</th>\n",
       "      <th>teamAwayAvgScoredGoals8</th>\n",
       "      <th>teamAwayAvgGottenGoals8</th>\n",
       "      <th>teamAwayAvgTeamPoints8</th>\n",
       "      <th>teamAwayAvgScoredGoals9</th>\n",
       "      <th>teamAwayAvgGottenGoals9</th>\n",
       "      <th>teamAwayAvgTeamPoints9</th>\n",
       "      <th>teamAwayAvgScoredGoals10</th>\n",
       "      <th>teamAwayAvgGottenGoals10</th>\n",
       "      <th>teamAwayAvgTeamPoints10</th>\n",
       "      <th>resultClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>109.40</td>\n",
       "      <td>61.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.625</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>100</td>\n",
       "      <td>87</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>136.28</td>\n",
       "      <td>55.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2:3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>131</td>\n",
       "      <td>81</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>155.43</td>\n",
       "      <td>48.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.375</td>\n",
       "      <td>1.875</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3:3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>124.65</td>\n",
       "      <td>279.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>59.13</td>\n",
       "      <td>50.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.375</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0:1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    teamHomeId  teamAwayId  matchDay  season  teamHomeValue  teamAwayValue  \\\n",
       "90           7          54        11    2009         109.40          61.98   \n",
       "93         100          87        11    2009         136.28          55.00   \n",
       "91         131          81        11    2009         155.43          48.78   \n",
       "92          16          40        11    2009         124.65         279.55   \n",
       "94          65          55        11    2009          59.13          50.88   \n",
       "\n",
       "    teamHomeAvgScoredGoals1  teamHomeAvgGottenGoals1  teamHomeAvgTeamPoints1  \\\n",
       "90                      1.0                      1.0                     1.0   \n",
       "93                      3.0                      3.0                     1.0   \n",
       "91                      0.0                      0.0                     1.0   \n",
       "92                      0.0                      1.0                     0.0   \n",
       "94                      0.0                      0.0                     1.0   \n",
       "\n",
       "    teamHomeAvgScoredGoals2  ...  teamAwayAvgScoredGoals8  \\\n",
       "90                      1.5  ...                    0.625   \n",
       "93                      1.5  ...                    0.625   \n",
       "91                      1.0  ...                    1.500   \n",
       "92                      0.5  ...                    1.875   \n",
       "94                      0.5  ...                    1.500   \n",
       "\n",
       "    teamAwayAvgGottenGoals8  teamAwayAvgTeamPoints8  teamAwayAvgScoredGoals9  \\\n",
       "90                    2.625                   0.125                 0.666667   \n",
       "93                    1.750                   0.500                 0.777778   \n",
       "91                    1.375                   1.875                 1.444444   \n",
       "92                    0.875                   2.000                 1.777778   \n",
       "94                    1.250                   1.375                 1.444444   \n",
       "\n",
       "    teamAwayAvgGottenGoals9  teamAwayAvgTeamPoints9  teamAwayAvgScoredGoals10  \\\n",
       "90                 2.555556                0.111111                       0.7   \n",
       "93                 1.666667                0.777778                       1.0   \n",
       "91                 1.333333                1.777778                       1.5   \n",
       "92                 0.888889                1.888889                       1.7   \n",
       "94                 1.222222                1.333333                       1.3   \n",
       "\n",
       "    teamAwayAvgGottenGoals10  teamAwayAvgTeamPoints10  resultClass  \n",
       "90                       2.3                      0.4          2:0  \n",
       "93                       1.8                      0.8          2:3  \n",
       "91                       1.4                      1.7          3:3  \n",
       "92                       0.9                      1.8          0:0  \n",
       "94                       1.2                      1.2          0:1  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "match_df = pickle.load(open(\"data/prepped_match_df.pck\", \"rb\"))\n",
    "print(f\"Dataset loaded: {match_df.shape}\")\n",
    "match_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22124710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = LabelEncoder()\n",
    "match_df[\"resultClass\"] = enc.fit_transform(match_df[\"resultClass\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "476a1dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (3865, 66)\n",
      "Test set: (967, 66)\n"
     ]
    }
   ],
   "source": [
    "# Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    match_df.drop(\"resultClass\", axis=1), \n",
    "    match_df[\"resultClass\"], \n",
    "    test_size=0.2, \n",
    "    shuffle=False  # Time series data\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54dbd15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Custom Kicktipp scorer ready\n",
      "‚úÖ Time Series Cross-Validation ready (5 splits)\n"
     ]
    }
   ],
   "source": [
    "# Custom Kicktipp Scorer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def kicktipp_score(y_true, y_pred, **kwargs):\n",
    "    \"\"\"Custom scoring function for Kicktipp predictions\"\"\"\n",
    "    # Convert to int64 for consistency\n",
    "    y_true = y_true.astype('int64') if hasattr(y_true, 'astype') else np.array(y_true, dtype='int64')\n",
    "    y_pred = y_pred.astype('int64') if hasattr(y_pred, 'astype') else np.array(y_pred, dtype='int64')\n",
    "    \n",
    "    # Decode predictions back to score format\n",
    "    y_true_decoded = [x.split(\":\") for x in enc.inverse_transform(y_true)]\n",
    "    y_pred_decoded = [x.split(\":\") for x in enc.inverse_transform(y_pred)]\n",
    "    \n",
    "    score_value = 0\n",
    "    for true, pred in zip(y_true_decoded, y_pred_decoded):\n",
    "        # Exact match: 5 points\n",
    "        if true[0] == pred[0] and true[1] == pred[1]:\n",
    "            score_value += 5\n",
    "        # Goal difference correct: 3 points\n",
    "        elif (int(true[0]) - int(true[1])) == (int(pred[0]) - int(pred[1])):\n",
    "            score_value += 3\n",
    "        # Winner correct: 1 point\n",
    "        elif ((true[0] > true[1]) and (pred[0] > pred[1])) or \\\n",
    "             ((true[0] < true[1]) and (pred[0] < pred[1])) or \\\n",
    "             ((true[0] == true[1]) and (pred[0] == pred[1])):\n",
    "            score_value += 1\n",
    "    \n",
    "    return round(score_value / (len(y_true)/306))  # Normalize to Kicktipp scale\n",
    "\n",
    "kicktipp_scorer = make_scorer(kicktipp_score, greater_is_better=True)\n",
    "print(\"‚úÖ Custom Kicktipp scorer ready\")\n",
    "\n",
    "# Cross-Validation Setup\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "print(\"‚úÖ Time Series Cross-Validation ready (5 splits)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "540984a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Baseline (majority class): 301 points\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model\n",
    "from collections import Counter\n",
    "\n",
    "# Always predict most frequent class\n",
    "majority_class = Counter(y_train).most_common(1)[0][0]\n",
    "baseline_predictions = np.full(len(y_test), majority_class)\n",
    "baseline_score = kicktipp_score(y_test, baseline_predictions)\n",
    "\n",
    "print(f\"üìä Baseline (majority class): {baseline_score} points\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9668db",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09ca3ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≥ Setting up RandomForest with comprehensive hyperparameter search...\n",
      "üìä Hyperparameter space: 35,814,240 total combinations\n",
      "üìä Search iterations: 150 (0.0004% coverage)\n",
      "üöÄ Starting hyperparameter optimization...\n",
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Best Parameters: {'n_estimators': np.int64(325), 'min_samples_split': np.int64(6), 'min_samples_leaf': np.int64(2), 'max_leaf_nodes': np.int64(10), 'max_features': None, 'max_depth': np.int64(11), 'criterion': 'gini', 'bootstrap': True}\n",
      "üéØ Best CV Score: 343.4 points\n"
     ]
    }
   ],
   "source": [
    "# RandomForest with Comprehensive Hyperparameter Tuning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "print(\"üå≥ Setting up RandomForest with comprehensive hyperparameter search...\")\n",
    "\n",
    "# Comprehensive parameter grid\n",
    "param_distributions = {\n",
    "    'n_estimators': np.arange(100, 501, 25),           # 100, 125, 150, ..., 500\n",
    "    'max_depth': [None] + list(np.arange(5, 31, 2)),   # None, 5, 7, 9, ..., 29\n",
    "    'min_samples_split': np.arange(2, 21, 1),          # 2, 3, 4, ..., 20\n",
    "    'min_samples_leaf': np.arange(1, 16, 1),           # 1, 2, 3, ..., 15\n",
    "    'max_features': ['sqrt', 'log2', None] + list(np.arange(0.1, 1.0, 0.1)),  # sqrt, log2, None, 0.1-0.9\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_leaf_nodes': [None] + list(np.arange(10, 101, 10))  # None, 10, 20, ..., 100\n",
    "}\n",
    "\n",
    "# Calculate total combinations\n",
    "total_combinations = 1\n",
    "for param, values in param_distributions.items():\n",
    "    total_combinations *= len(values)\n",
    "\n",
    "print(f\"üìä Hyperparameter space: {total_combinations:,} total combinations\")\n",
    "print(f\"üìä Search iterations: 150 ({150/total_combinations*100:.4f}% coverage)\")\n",
    "\n",
    "# RandomForest model\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=150,  # Comprehensive search\n",
    "    cv=tscv,\n",
    "    scoring=kicktipp_scorer,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting hyperparameter optimization...\")\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "# Results\n",
    "best_params = rf_search.best_params_\n",
    "best_cv_score = rf_search.best_score_\n",
    "best_model = rf_search.best_estimator_\n",
    "\n",
    "print(f\"\\nüéØ Best Parameters: {best_params}\")\n",
    "print(f\"üéØ Best CV Score: {best_cv_score:.1f} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9fb3f867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üèÜ FINAL RESULTS\n",
      "==================================================\n",
      "üìä Baseline Score:        301 points\n",
      "üå≥ RandomForest CV Score: 343.4 points\n",
      "üå≥ RandomForest Test Score: 326 points\n",
      "üìà Improvement over baseline: +25 points\n",
      "==================================================\n",
      "‚úÖ SUCCESS: 25 points improvement!\n"
     ]
    }
   ],
   "source": [
    "# Final Model Evaluation\n",
    "predictions = best_model.predict(X_test)\n",
    "final_score = kicktipp_score(y_test, predictions)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"üèÜ FINAL RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Baseline Score:        {baseline_score} points\")\n",
    "print(f\"üå≥ RandomForest CV Score: {best_cv_score:.1f} points\")\n",
    "print(f\"üå≥ RandomForest Test Score: {final_score} points\")\n",
    "print(f\"üìà Improvement over baseline: +{final_score - baseline_score} points\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if final_score > baseline_score:\n",
    "    print(f\"‚úÖ SUCCESS: {final_score - baseline_score} points improvement!\")\n",
    "else:\n",
    "    print(f\"‚ùå Model performs worse than baseline by {baseline_score - final_score} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "349acfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Model saved as: classifier_20250928_125632.pck\n",
      "üíæ Encoder saved as: encoder.pck\n",
      "üíæ Final score: 326 points\n",
      "üíæ Best parameters: {'n_estimators': np.int64(325), 'min_samples_split': np.int64(6), 'min_samples_leaf': np.int64(2), 'max_leaf_nodes': np.int64(10), 'max_features': None, 'max_depth': np.int64(11), 'criterion': 'gini', 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "# Save Model and Encoder\n",
    "from datetime import datetime\n",
    "\n",
    "# Generate timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save best model\n",
    "model_filename = f\"classifier_{timestamp}.pck\"\n",
    "pickle.dump(best_model, open(model_filename, \"wb\"))\n",
    "\n",
    "# Save encoder (fixed filename)\n",
    "encoder_filename = \"encoder.pck\"\n",
    "pickle.dump(enc, open(encoder_filename, \"wb\"))\n",
    "\n",
    "print(f\"üíæ Model saved as: {model_filename}\")\n",
    "print(f\"üíæ Encoder saved as: {encoder_filename}\")\n",
    "print(f\"üíæ Final score: {final_score} points\")\n",
    "print(f\"üíæ Best parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59ac5de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Building Stacking Ensemble from Top 3 RandomForest models...\n",
      "üìä Available models from RandomizedSearchCV: 150\n",
      "üìä Top 3 CV scores: [343.4 340.8 340. ]\n",
      "‚úÖ Model 1 trained with CV score: 343.4\n",
      "‚úÖ Model 2 trained with CV score: 340.8\n",
      "‚úÖ Model 3 trained with CV score: 340.0\n",
      "\n",
      "üèóÔ∏è Creating Stacking Ensemble with 3 base models...\n",
      "üöÄ Training Stacking Ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1380: RuntimeWarning: Number of classes in training fold (47) does not match total number of classes (49). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1380: RuntimeWarning: Number of classes in training fold (48) does not match total number of classes (49). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1380: RuntimeWarning: Number of classes in training fold (47) does not match total number of classes (49). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s finished\n",
      "/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1380: RuntimeWarning: Number of classes in training fold (47) does not match total number of classes (49). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1380: RuntimeWarning: Number of classes in training fold (48) does not match total number of classes (49). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1380: RuntimeWarning: Number of classes in training fold (47) does not match total number of classes (49). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.0s finished\n",
      "/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1380: RuntimeWarning: Number of classes in training fold (47) does not match total number of classes (49). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1380: RuntimeWarning: Number of classes in training fold (47) does not match total number of classes (49). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1380: RuntimeWarning: Number of classes in training fold (48) does not match total number of classes (49). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Stacking Ensemble Test Score: 315 points\n",
      "\n",
      "üìä Individual model performance on test set:\n",
      "  rf_model_1: 326 points\n",
      "  rf_model_2: 324 points\n",
      "  rf_model_3: 329 points\n"
     ]
    }
   ],
   "source": [
    "# Stacking Ensemble: Top 3 RandomForest Models (corrected)\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "print(\"üèóÔ∏è Building Stacking Ensemble from Top 3 RandomForest models...\")\n",
    "\n",
    "# Extrahiere Top 3 Modelle aus der rf_search (nicht pipeline_search)\n",
    "cv_results = pd.DataFrame(rf_search.cv_results_)\n",
    "cv_results_sorted = cv_results.sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "print(f\"üìä Available models from RandomizedSearchCV: {len(cv_results)}\")\n",
    "print(f\"üìä Top 3 CV scores: {cv_results_sorted['mean_test_score'].head(3).values}\")\n",
    "\n",
    "# Erstelle die Top 3 RandomForest Modelle (ohne Pipeline)\n",
    "top_3_models = []\n",
    "for i in range(3):\n",
    "    params = cv_results_sorted.iloc[i]['params']\n",
    "    \n",
    "    # Erstelle RandomForest mit den Top-Parametern\n",
    "    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    rf_model.set_params(**params)\n",
    "    \n",
    "    # Trainiere das Modell\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    top_3_models.append((f'rf_model_{i+1}', rf_model))\n",
    "    \n",
    "    print(f\"‚úÖ Model {i+1} trained with CV score: {cv_results_sorted.iloc[i]['mean_test_score']:.1f}\")\n",
    "\n",
    "print(f\"\\nüèóÔ∏è Creating Stacking Ensemble with {len(top_3_models)} base models...\")\n",
    "\n",
    "# Stacking Classifier mit LogisticRegression als Meta-Learner\n",
    "# TimeSeriesSplit funktioniert nicht mit StackingClassifier, nutze Standard KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=top_3_models,\n",
    "    final_estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=42),  # Standard CV f√ºr Stacking\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"üöÄ Training Stacking Ensemble...\")\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Stacking Predictions\n",
    "stacking_predictions = stacking_classifier.predict(X_test)\n",
    "stacking_score = kicktipp_score(y_test, stacking_predictions)\n",
    "\n",
    "print(f\"\\nüéØ Stacking Ensemble Test Score: {stacking_score} points\")\n",
    "\n",
    "# Vergleiche auch die individuellen Modelle\n",
    "print(f\"\\nüìä Individual model performance on test set:\")\n",
    "for i, (name, model) in enumerate(top_3_models):\n",
    "    individual_predictions = model.predict(X_test)\n",
    "    individual_score = kicktipp_score(y_test, individual_predictions)\n",
    "    print(f\"  {name}: {individual_score} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82fc5680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üèÜ FINAL MODEL COMPARISON\n",
      "============================================================\n",
      "üìä Baseline Score:        301 points\n",
      "üå≥ Original RandomForest: 326 points\n",
      "üèóÔ∏è Stacking Ensemble:     315 points\n",
      "============================================================\n",
      "üìà Original RF improvement:  +25 points\n",
      "üìà Stacking improvement:     +14 points\n",
      "üèóÔ∏è Stacking vs Original:     -11 points\n",
      "\n",
      "ü§î Original RF still better by 11 points\n",
      "\n",
      "üèÜ WINNER: Original RF with 326 points\n",
      "\n",
      "üí° COMPLEXITY vs PERFORMANCE:\n",
      "  üå≥ Original RF: 326 points (1 model)\n",
      "  üèóÔ∏è Stacking:    315 points (3 models + meta-learner)\n",
      "\n",
      "üèÜ RECOMMENDATION: Use Original RandomForest!\n",
      "   ‚úÖ Simpler model with comparable performance\n"
     ]
    }
   ],
   "source": [
    "# Final Comparison: Original RF vs Stacking (Clean Version)\n",
    "print(\"=\" * 60)\n",
    "print(\"üèÜ FINAL MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä Baseline Score:        {baseline_score} points\")\n",
    "print(f\"üå≥ Original RandomForest: {final_score} points\")\n",
    "print(f\"üèóÔ∏è Stacking Ensemble:     {stacking_score} points\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "original_improvement = final_score - baseline_score\n",
    "stacking_improvement = stacking_score - baseline_score\n",
    "stacking_vs_original = stacking_score - final_score\n",
    "\n",
    "print(f\"üìà Original RF improvement:  +{original_improvement} points\")\n",
    "print(f\"üìà Stacking improvement:     +{stacking_improvement} points\")\n",
    "print(f\"üèóÔ∏è Stacking vs Original:     {stacking_vs_original:+} points\")\n",
    "\n",
    "if stacking_score > final_score:\n",
    "    print(f\"\\n‚úÖ STACKING WINS! Ensemble improved by {stacking_vs_original} points\")\n",
    "    best_final_model = stacking_classifier\n",
    "    best_final_score = stacking_score\n",
    "    best_approach = \"Stacking\"\n",
    "else:\n",
    "    print(f\"\\nü§î Original RF still better by {-stacking_vs_original} points\")\n",
    "    best_final_model = best_model\n",
    "    best_final_score = final_score\n",
    "    best_approach = \"Original RF\"\n",
    "\n",
    "print(f\"\\nüèÜ WINNER: {best_approach} with {best_final_score} points\")\n",
    "\n",
    "# Komplexit√§t vs Performance\n",
    "print(f\"\\nüí° COMPLEXITY vs PERFORMANCE:\")\n",
    "print(f\"  üå≥ Original RF: {final_score:3.0f} points (1 model)\")\n",
    "print(f\"  üèóÔ∏è Stacking:    {stacking_score:3.0f} points (3 models + meta-learner)\")\n",
    "\n",
    "if stacking_vs_original >= 3:\n",
    "    print(f\"\\nüèÜ RECOMMENDATION: Use Stacking Ensemble!\")\n",
    "    print(f\"   ‚úÖ Significant improvement: +{stacking_vs_original} points\")\n",
    "else:\n",
    "    print(f\"\\nüèÜ RECOMMENDATION: Use Original RandomForest!\")\n",
    "    print(f\"   ‚úÖ Simpler model with comparable performance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebdeafa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Best model (Original RF) saved as: classifier_20250928_130858.pck\n",
      "üíæ Model type: RandomForestClassifier\n",
      "üíæ Encoder saved as: encoder.pck\n",
      "üíæ Final score: 326 points\n",
      "üíæ Improvement over baseline: +25 points\n"
     ]
    }
   ],
   "source": [
    "# Save Best Model and Encoder (Clean Version)\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Determine which model performed better\n",
    "if stacking_score > final_score:\n",
    "    model_to_save = stacking_classifier\n",
    "    score_to_save = stacking_score\n",
    "    approach_name = \"Stacking\"\n",
    "    model_type = \"StackingClassifier with 3 RandomForest base models\"\n",
    "else:\n",
    "    model_to_save = best_model\n",
    "    score_to_save = final_score\n",
    "    approach_name = \"Original RF\"\n",
    "    model_type = \"RandomForestClassifier\"\n",
    "\n",
    "model_filename = f\"classifier_{timestamp}.pck\"\n",
    "pickle.dump(model_to_save, open(model_filename, \"wb\"))\n",
    "\n",
    "# Save encoder\n",
    "encoder_filename = \"encoder.pck\"\n",
    "pickle.dump(enc, open(encoder_filename, \"wb\"))\n",
    "\n",
    "print(f\"üíæ Best model ({approach_name}) saved as: {model_filename}\")\n",
    "print(f\"üíæ Model type: {model_type}\")\n",
    "print(f\"üíæ Encoder saved as: {encoder_filename}\")\n",
    "print(f\"üíæ Final score: {score_to_save} points\")\n",
    "print(f\"üíæ Improvement over baseline: +{score_to_save - baseline_score} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d7350e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Building Stacking Ensemble from Top 3 RandomForest models...\n",
      "üìä Available models from RandomizedSearchCV: 150\n",
      "üìä Top 3 CV scores: [346.8 345.8 345.4]\n",
      "‚úÖ Model 1 trained with CV score: 346.8\n",
      "‚úÖ Model 2 trained with CV score: 345.8\n",
      "‚úÖ Model 3 trained with CV score: 345.4\n",
      "\n",
      "üèóÔ∏è Creating Stacking Ensemble with 3 base models...\n",
      "üöÄ Training Stacking Ensemble...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cross_val_predict only works for partitions",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 490, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 607, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/maxlautenbach/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 1225, in cross_val_predict\n    raise ValueError(\"cross_val_predict only works for partitions\")\nValueError: cross_val_predict only works for partitions\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     39\u001b[39m stacking_classifier = StackingClassifier(\n\u001b[32m     40\u001b[39m     estimators=top_3_models,\n\u001b[32m     41\u001b[39m     final_estimator=LogisticRegression(random_state=\u001b[32m42\u001b[39m, max_iter=\u001b[32m1000\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     45\u001b[39m )\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müöÄ Training Stacking Ensemble...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mstacking_classifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Stacking Predictions\u001b[39;00m\n\u001b[32m     51\u001b[39m stacking_predictions = stacking_classifier.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:63\u001b[39m, in \u001b[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     66\u001b[39m args_msg = [\n\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(name, arg)\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001b[32m     69\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:717\u001b[39m, in \u001b[36mStackingClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    716\u001b[39m     fit_params[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = sample_weight\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:254\u001b[39m, in \u001b[36m_BaseStacking.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cv, \u001b[33m\"\u001b[39m\u001b[33mrandom_state\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m cv.random_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    252\u001b[39m         cv.random_state = np.random.RandomState()\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     predictions = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_val_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstack_method_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdrop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[38;5;28mself\u001b[39m.stack_method_ = [\n\u001b[32m    272\u001b[39m     meth\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.stack_method_, all_estimators)\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m est != \u001b[33m\"\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    275\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/joblib/parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/joblib/parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/joblib/parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/football_match_prediction/.venv/lib/python3.11/site-packages/joblib/parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: cross_val_predict only works for partitions"
     ]
    }
   ],
   "source": [
    "# Stacking Ensemble: Top 3 RandomForest Models\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "print(\"üèóÔ∏è Building Stacking Ensemble from Top 3 RandomForest models...\")\n",
    "\n",
    "# Extrahiere Top 3 Modelle aus der RandomizedSearchCV\n",
    "cv_results = pd.DataFrame(pipeline_search.cv_results_)\n",
    "cv_results_sorted = cv_results.sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "print(f\"üìä Available models from RandomizedSearchCV: {len(cv_results)}\")\n",
    "print(f\"üìä Top 3 CV scores: {cv_results_sorted['mean_test_score'].head(3).values}\")\n",
    "\n",
    "# Erstelle die Top 3 RandomForest Modelle\n",
    "top_3_models = []\n",
    "for i in range(3):\n",
    "    params = cv_results_sorted.iloc[i]['params']\n",
    "    \n",
    "    # Erstelle Pipeline mit gleicher Struktur\n",
    "    model_pipeline = Pipeline([\n",
    "        ('feature_engineering', HomeAwayDifferenceTransformer(verbose=False)),\n",
    "        ('rf', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "    ])\n",
    "    \n",
    "    # Setze die Parameter\n",
    "    model_pipeline.set_params(**params)\n",
    "    \n",
    "    # Trainiere das Modell\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    top_3_models.append((f'rf_model_{i+1}', model_pipeline))\n",
    "    \n",
    "    print(f\"‚úÖ Model {i+1} trained with CV score: {cv_results_sorted.iloc[i]['mean_test_score']:.1f}\")\n",
    "\n",
    "print(f\"\\nüèóÔ∏è Creating Stacking Ensemble with {len(top_3_models)} base models...\")\n",
    "\n",
    "# Stacking Classifier mit LogisticRegression als Meta-Learner\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=top_3_models,\n",
    "    final_estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
    "    cv=tscv,  # Gleiche CV-Strategie\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"üöÄ Training Stacking Ensemble...\")\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Stacking Predictions\n",
    "stacking_predictions = stacking_classifier.predict(X_test)\n",
    "stacking_score = kicktipp_score(y_test, stacking_predictions)\n",
    "\n",
    "print(f\"\\nüéØ Stacking Ensemble Test Score: {stacking_score} points\")\n",
    "\n",
    "# Vergleiche auch die individuellen Modelle\n",
    "print(f\"\\nüìä Individual model performance on test set:\")\n",
    "for i, (name, model) in enumerate(top_3_models):\n",
    "    individual_predictions = model.predict(X_test)\n",
    "    individual_score = kicktipp_score(y_test, individual_predictions)\n",
    "    print(f\"  {name}: {individual_score} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Comparison: All Approaches\n",
    "print(\"=\" * 70)\n",
    "print(\"üèÜ FINAL MODEL COMPARISON - ALL APPROACHES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üìä Baseline Score:              {baseline_score} points\")\n",
    "print(f\"üå≥ Original RandomForest:       {final_score} points\")\n",
    "print(f\"üîÑ Pipeline (Feature Eng.):     {pipeline_final_score} points\")\n",
    "print(f\"üèóÔ∏è Stacking Ensemble:           {stacking_score} points\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Alle Verbesserungen berechnen\n",
    "all_scores = {\n",
    "    'Baseline': baseline_score,\n",
    "    'Original RF': final_score,\n",
    "    'Pipeline RF': pipeline_final_score,\n",
    "    'Stacking': stacking_score\n",
    "}\n",
    "\n",
    "improvements = {name: score - baseline_score for name, score in all_scores.items() if name != 'Baseline'}\n",
    "\n",
    "print(\"üìà IMPROVEMENTS over baseline:\")\n",
    "for approach, improvement in improvements.items():\n",
    "    print(f\"  {approach:15}: +{improvement:4.0f} points\")\n",
    "\n",
    "# Bester Ansatz\n",
    "best_approach_name = max(all_scores, key=all_scores.get)\n",
    "best_score_final = all_scores[best_approach_name]\n",
    "\n",
    "print(f\"\\nüèÜ OVERALL WINNER: {best_approach_name} with {best_score_final} points!\")\n",
    "\n",
    "# Modell-Komplexit√§t vs Performance\n",
    "print(f\"\\nüí° COMPLEXITY vs PERFORMANCE ANALYSIS:\")\n",
    "print(f\"  üìä Baseline:        {baseline_score:3.0f} points (Trivial)\")\n",
    "print(f\"  üå≥ Original RF:     {final_score:3.0f} points (Medium complexity)\")\n",
    "print(f\"  üîÑ Pipeline RF:     {pipeline_final_score:3.0f} points (Medium+ complexity)\")  \n",
    "print(f\"  üèóÔ∏è Stacking:        {stacking_score:3.0f} points (High complexity)\")\n",
    "\n",
    "# Finale Empfehlung\n",
    "stacking_improvement = stacking_score - max(final_score, pipeline_final_score)\n",
    "if stacking_improvement >= 5:\n",
    "    print(f\"\\nüèÜ RECOMMENDATION: Stacking Ensemble!\")\n",
    "    print(f\"   ‚úÖ Best performance: {stacking_score} points\")\n",
    "    print(f\"   ‚úÖ Significant improvement: +{stacking_improvement} points\")\n",
    "    final_best_model = stacking_classifier\n",
    "elif pipeline_final_score > final_score:\n",
    "    print(f\"\\nüèÜ RECOMMENDATION: Pipeline with Feature Engineering!\")\n",
    "    print(f\"   ‚úÖ Good performance with reasonable complexity\")\n",
    "    print(f\"   ‚úÖ Feature engineering benefits: +{pipeline_final_score - final_score} points\")\n",
    "    final_best_model = pipeline_best_model\n",
    "else:\n",
    "    print(f\"\\nüèÜ RECOMMENDATION: Original RandomForest!\")\n",
    "    print(f\"   ‚úÖ Simple and effective: {final_score} points\")\n",
    "    final_best_model = best_model\n",
    "\n",
    "print(f\"\\nüíæ Best model ready for saving: {type(final_best_model).__name__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1cd0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e780f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dab9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Best Model and Encoder\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the best performing model\n",
    "model_filename = f\"classifier_{timestamp}.pck\"\n",
    "pickle.dump(stacking_classifier, open(model_filename, \"wb\"))\n",
    "\n",
    "# Save encoder\n",
    "encoder_filename = \"encoder.pck\"\n",
    "pickle.dump(enc, open(encoder_filename, \"wb\"))\n",
    "\n",
    "print(f\"üíæ Stacking model saved as: {model_filename}\")\n",
    "print(f\"üíæ Encoder saved as: {encoder_filename}\")\n",
    "print(f\"üíæ Final score: {stacking_score} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2183b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
